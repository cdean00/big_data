{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Tuesday Exercise\n",
    "\n",
    "**Assignment**: This exercise will use pandas to explore tweet data.  Specifically, you will:\n",
    "  \n",
    "* Read a file of tweets into a dataframe\n",
    "* Use pandas to describe and analyze the data\n",
    "* Discuss how these methods might be used by relevant firms\n",
    "\n",
    "For this exercise, you will have to complete all the tasks within this notebook, save the entire notebook, and then upload into the Week 4 Tuesday Assignment for your group on BlackBoard. Save this notebook with a new name with the following format:\n",
    "\n",
    "**Week_4_Tues_Exercise_Group_group_number.ipynb**\n",
    "\n",
    "These in-class exercises are designed to allow you to explore Python with your group and **DO NOT** include step-by-step directions or answers that have only one possibility. Use your team and other resources to determine how best to complete them. Make sure before you turn in your notebook that it runs without errors and the requested output is visible in the notebook. If you go through multiple steps in your code, make sure all those steps are included so that we can evaluate your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, unzip and read the tweet data from the file from the datasets folder named 'pokemon.zip' into a dataframe and examine the dataset.\n",
    "\n",
    "**Analyze Tweet Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code block is to make the tweets_list function available. You don't need to modify anything here, just run it.\n",
    "\n",
    "import json\n",
    "\n",
    "def tweets_list(filename):\n",
    "    \"\"\"\n",
    "    Read lines from filepath and file into a list of dictionaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "    \"\"\"\n",
    "    tweets = []\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "    return tweets     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read file with tweet data into a variable using tweets_list\n",
    "\n",
    "data = tweets_list('./datasets/pokemon.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What datatype is data\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, read the data variable into a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "tweet_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets are in the tweet dataframe?\n",
    "len(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'contributors', u'coordinates', u'created_at', u'entities',\n",
       "       u'extended_entities', u'favorite_count', u'favorited', u'filter_level',\n",
       "       u'geo', u'id', u'id_str', u'in_reply_to_screen_name',\n",
       "       u'in_reply_to_status_id', u'in_reply_to_status_id_str',\n",
       "       u'in_reply_to_user_id', u'in_reply_to_user_id_str', u'is_quote_status',\n",
       "       u'lang', u'place', u'possibly_sensitive', u'quoted_status',\n",
       "       u'quoted_status_id', u'quoted_status_id_str', u'retweet_count',\n",
       "       u'retweeted', u'retweeted_status', u'source', u'text', u'timestamp_ms',\n",
       "       u'truncated', u'user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the tweets are retweets? If they are not retweeted, they have no data.\n",
    "tweet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the tweets are retweets? If they are not retweeted, they have no data.\n",
    "len(tweet_df[tweet_df.retweeted_status.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the tweets are determined to be English?\n",
    "len(tweet_df[tweet_df.lang == 'en'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With nested data like this, you can unpack individual columns with multiple values into their own column. The syntax is beyond the scope of this course, but is as follows:\n",
    "```\n",
    "dataframe['new column'] = dataframe['column to unpack'].map(lambda tweet: tweet['key to unpack'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This code creates a new column called 'user_location' from the nested data in the user column\n",
    "tweet_df['user_location'] = tweet_df['user'].map(lambda tweet: tweet['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets originated in the user location of Hyrule?\n",
    "tweet_df['user_location'][tweet_df['user_location'] == 'Hyrule'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 1\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "* How do you think the Pokémon Company uses streaming data like this?\n",
    " * The Pokemon Company could use streaming data to track trending popularity of their products or to track in real-time a recent marketing campaign.\n",
    "* What specific applications could it have for product development?\n",
    " * They could track trends in real-time immediately after a product launch to determine if changes need to made in marketing or the supply chain to adjust for slow sales.\n",
    "* What other streaming datasets (internal or external) might the Pokémon Company use with the Twitter data?\n",
    " * They could track competitor product trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 2\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "How could you determine if a specific tweet had a negative or positive sentiment? (use specific fields from the tweet data in your response) \n",
    "\n",
    "* Using the 'text' column, perform sentiment analysis whereby the Tweets are broken down into sub-sentences and analyzed for positive or negative connotations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 3\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "Picking a company where one of you works, what streaming data sources might be useful for you and what sorts of research questions could they inform?\n",
    "\n",
    "* SRP could combine internal meter data with Twitter streams to determine where an outage is occuring and respond proactively to assess and fix the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 4\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "Review this post about the Twitter metadata you were using- https://blog.twitter.com/2013/introducing-new-metadata-for-tweets\n",
    "\n",
    "* How might some tweets lead to the language attribute being inaccurate or undetermined?\n",
    " * Tweets that contain emoticons or other symbols could cause the language algorithm to not be able to determine the correct language. In addition slang might also cause the alogorithm to pick the wrong language (e.g. American English vs. British English).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
